"""task2_of_internship.ipynb

# **GRIP: THE SPARKS FOUNDATION**

**Data Science & Business Analytics**

**Author : SARTHAK PARASHAR**

Task :- 2

**Prediction using Unsupervised ML**

**Problem Statement-**

● From the given ‘Iris’ dataset, predict the optimum number of clusters and represent it visually.

● Use R or Python or perform this task

● **Dataset ** : https://bit.ly/3kXTdox

"""

# Importing the libraries

import numpy as np

import matplotlib.pyplot as plt

import pandas as pd

import seaborn as sns

from sklearn import datasets

from sklearn.cluster import KMeans

# Load the iris dataset

iris = datasets.load_iris()

df = pd.DataFrame(iris.data, columns = iris.feature_names)

df.head()

df.shape

df.describe()

# Correlation Between Variables

correlation =df.corr() 

correlation

# Heatmap Between Correlated Data

plt.figure(figsize=(12,8))

sns.set()

sns.heatmap(df.corr(),annot= True, cmap="nipy_spectral")

plt.show()

# Finding optimum number of Clusters for K-Means

plt.figure(figsize=(12,8))

x=df.iloc[:,[0,1,2,3]].values

wcss=[]

for i in range(1,11):

    kmeans=KMeans(n_clusters = i, init = 'k-means++',max_iter = 300, n_init = 10, random_state = 0).fit(x)

    wcss.append(kmeans.inertia_)

    

plt.plot(range(1, 11), wcss, 'bo--')

plt.title('The elbow method')

plt.xlabel('Number of clusters')

plt.ylabel('WCSS')

plt.show()

#Here I apply k-means Clustering Algorithm

kmeans=KMeans(n_clusters = 3, init = 'k-means++',max_iter = 300, n_init = 10, random_state = 0)

y_kmeans=kmeans.fit_predict(x)

plt.figure(figsize=(12,8))

plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Iris-setosa')

plt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Iris-versicolour')

plt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1],s = 100, c = 'green', label = 'Iris-virginica')

plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s = 100, c = 'yellow', label = 'Centroids')

plt.legend()

plt.show()

#THE END 

#THANK YOU...
